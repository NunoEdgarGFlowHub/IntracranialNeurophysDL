{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CNNs to Decode ECoG Data\n",
    "Run the first few cells to normalize Local / Colab, then proceed below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    os.chdir('..')\n",
    "    if not (Path.cwd() / '.kaggle').is_dir():\n",
    "        # Configure kaggle\n",
    "        files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        !pip install -q kaggle\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !mv kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "    if not (Path.cwd() / 'repo').is_dir():\n",
    "        # Download the workshop repo and change to its directory\n",
    "        # For now edit the username/password. This requirement will be removed when the repo is made public.\n",
    "        !git clone https://github.com/SachsLab/IntracranialNeurophysDL.git\n",
    "        os.chdir('IntracranialNeurophysDL')\n",
    "    IN_COLAB = True\n",
    "    # Setup tensorflow 2.0\n",
    "    !pip install -q tensorflow-gpu==2.0.0-alpha0\n",
    "    import tensorflow as tf\n",
    "    # Setup tensorboard callback\n",
    "    !pip install tensorboardcolab\n",
    "    from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
    "    tbc=TensorBoardColab(startup_waiting_time=30)\n",
    "    tensorboard_callback = TensorBoardColabCallback(tbc)\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    if Path.cwd().stem == 'notebooks':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "    # Clear any logs from previous runs\n",
    "    if (Path.cwd() / 'logs').is_dir():\n",
    "        import platform\n",
    "        if platform.system() == 'Windows':\n",
    "            !rmdir /S /Q logs\n",
    "        else:\n",
    "            !rm -Rf logs\n",
    "    # Setup tensorboard callback\n",
    "    import tensorflow as tf\n",
    "    import datetime\n",
    "    %load_ext tensorboard.notebook\n",
    "    log_dir = Path.cwd() / \"logs\" / datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download and unzip data\n",
    "datadir = Path.cwd() / 'data' / 'kjm_ecog'\n",
    "if not (datadir / 'converted').is_dir():\n",
    "    !kaggle datasets download -d cboulay/kjm-ecog-faces-basic\n",
    "    print(\"Finished downloading. Now extracting contents...\")\n",
    "    data_path = Path('kjm-ecog-faces-basic.zip')\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(datadir / 'converted' / 'faces_basic')\n",
    "    data_path.unlink()\n",
    "    print(\"Finished extracting data.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data from one participant\n",
    "See 02_02 for an explanation.\n",
    "However, this time we are loading the full-band data at the original sampling rate.\n",
    "Let's pretend that we don't know anything about what signal features might be important.\n",
    "Even if we think we know what signal features might be important, sometimes it's nice\n",
    "to remove our bias and let the machine find the features for us."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data.utils.fileio import from_neuropype_h5\n",
    "\n",
    "PTRAIN = 0.8\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# Load data from one participant.\n",
    "SUB_ID = 'de'\n",
    "test_file = datadir / 'converted' / 'faces_basic' / (SUB_ID + '_full.h5')\n",
    "chunks = from_neuropype_h5(test_file)\n",
    "chunk_names = [_[0] for _ in chunks]\n",
    "chunk = chunks[chunk_names.index('signals')][1]\n",
    "ax_types = [_['type'] for _ in chunk['axes']]\n",
    "instance_axis = chunk['axes'][ax_types.index('instance')]\n",
    "n_trials = len(instance_axis['data'])\n",
    "X = chunk['data']\n",
    "Y = instance_axis['data']['Marker'].values.reshape(-1, 1)\n",
    "n_trials = X.shape[0]\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Convert Y from strings to integers.\n",
    "classes, y = np.unique(Y, return_inverse=True)\n",
    "n_classes = len(classes)\n",
    "n_trials = len(y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=PTRAIN)\n",
    "n_train = len(y_train)\n",
    "n_valid = len(y_valid)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "\n",
    "def preprocess_fn(x_dat, y_dat):\n",
    "    x_dat = tf.cast(x_dat, tf.float32)\n",
    "    y_dat = tf.one_hot(tf.cast(y_dat, tf.uint8), n_classes)\n",
    "    return x_dat, y_dat\n",
    "ds_train = ds_train.map(preprocess_fn)\n",
    "ds_valid = ds_valid.map(preprocess_fn)\n",
    "ds_train = ds_train.shuffle(int(n_trials * PTRAIN) + 1).batch(BATCH_SIZE, drop_remainder=True).repeat()  # , drop_remainder=True?\n",
    "ds_valid = ds_valid.batch(BATCH_SIZE).repeat()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create our model\n",
    "As in 02_02, our objective is to decode the stimulus class ('ISI', 'face', or 'house')\n",
    "from the ECoG data.\n",
    "Let's start off with a model that someone else developed for similar purposes.\n",
    "\n",
    "[One for EEG](https://iopscience.iop.org/article/10.1088/1741-2552/aaf3f6)\n",
    "\n",
    "[CNNs with autoencoders](https://iopscience.iop.org/article/10.1088/1741-2552/aaf13f/pdf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input(shape=(X.shape[1],))\n",
    "# dat_in_model = tf.keras.layers.Dense(3, activation='linear')(inputs)\n",
    "# outputs = tf.keras.layers.Softmax()(dat_in_model)  # Convert to probability scores, summing to 1\n",
    "# model = tf.keras.Model(inputs, outputs)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}