{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-vAyK4-TRWD"
   },
   "source": [
    "## Applied Deep Learning in Intracranial Neurophysiology Workshop\n",
    "### Adversarial Domain Adaptation for Stable Brain-Machine Interfaces https://arxiv.org/pdf/1810.00045.pdf\n",
    "\n",
    "This notebook is part of the [SachsLab Workshop for Intracranial Neurophysiology and Deep Learning](https://github.com/SachsLab/IntracranialNeurophysDL), prepared generously by [Dr. Ali Farshchian](https://www.researchgate.net/profile/Ali_Farshchian). The original version can be found on his [GitHub page](https://github.com/farshchian/ADAN).\n",
    "\n",
    "<table><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/08_01_ADAN_Exercise.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cam1hTv8TRWF"
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1U7JR-OuTRWF"
   },
   "outputs": [],
   "source": [
    "# Normalize local and google colab environments.\n",
    "from pathlib import Path\n",
    "import os\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    import google.colab\n",
    "    os.chdir('..')\n",
    "    if Path.cwd().stem != 'IntracranialNeurophysDL':\n",
    "        if not (Path.cwd() / 'IntracranialNeurophysDL').is_dir():\n",
    "            # Download the workshop repo and change to its directory\n",
    "            !git clone --recursive https://github.com/SachsLab/IntracranialNeurophysDL.git\n",
    "        os.chdir('IntracranialNeurophysDL')\n",
    "    !pip install tensorflow==1.10.0\n",
    "    IN_COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    if Path.cwd().stem == 'notebooks':\n",
    "        os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyGRVUxMTRWH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from indl.adan import utils\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8d7lpM6BTRWJ"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LScutJaMTRWK"
   },
   "outputs": [],
   "source": [
    "datadir = Path.cwd() / 'data' / 'ADAN'\n",
    "data_files = [f for f in os.listdir(path=str(datadir)) if f.endswith('.mat')]\n",
    "data={}\n",
    "for i,f in enumerate(data_files):\n",
    "    raw_data = sio.loadmat(datadir/f, squeeze_me=True)\n",
    "    data['rate'+str(i)],data['EMG'+str(i)]=utils.load_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPHqouFETRWL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(2,2,(1,3))\n",
    "plt.imshow(np.transpose(data['rate0']),cmap='Spectral',extent=[0,100,0,96])\n",
    "plt.xlabel('time (%)')\n",
    "plt.ylabel('firing rate')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "t = np.linspace(0., 60., 1200, endpoint=True)\n",
    "plt.plot(t,data['EMG0'][:1200,0])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('EMG')\n",
    "plt.title('Flexor Carpi Radialis')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(t,data['EMG0'][:1200,11])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('EMG')\n",
    "plt.title('Extensor Carpi Radialis')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRUs7OUTTRWN"
   },
   "source": [
    "## Day-0 Decoder\n",
    "![ADAN](https://github.com/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/img/ADAN.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mR9ubRoXTRWO"
   },
   "source": [
    "### Decoder Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pWoWuuYTRWO"
   },
   "outputs": [],
   "source": [
    "spike_dim = 96\n",
    "emg_dim = 14\n",
    "latent_dim = 10\n",
    "batch_size = 64\n",
    "n_steps = 4\n",
    "n_layers = 1\n",
    "n_epochs = 400\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7ERjcIvTRWQ"
   },
   "source": [
    "### Decoder Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goNTwU1sTRWQ"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(seed=42)\n",
    "\n",
    "spike = tf.placeholder(tf.float32, (None,spike_dim), name='spike')\n",
    "emg = tf.placeholder(tf.float32, (None,emg_dim), name='emg')\n",
    "gamma = tf.placeholder(tf.float32)\n",
    "\n",
    "# complete the autoencoder function\n",
    "def autoencoder(input_, n_units=[64,32,latent_dim], reuse=False):\n",
    "    with tf.variable_scope('autoencoder', reuse=reuse):\n",
    "        return latent, logits\n",
    "\n",
    "latent,logits = autoencoder(spike)\n",
    "\n",
    "# complete the emg_decoder function\n",
    "def emg_decoder(latent, reuse=False):\n",
    "    with tf.variable_scope('emg_decoder', reuse=reuse):\n",
    "        return emg_hat\n",
    "\n",
    "emg_hat = emg_decoder(latent)\n",
    "emg_hat = tf.identity(emg_hat, name='emg_hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1kAB1TATRWS"
   },
   "source": [
    "### Decoder Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtNCDhM4TRWT"
   },
   "outputs": [],
   "source": [
    "# finish this\n",
    "ae_loss = \n",
    "emg_loss = \n",
    "total_loss = \n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdZ-WS3QTRWV"
   },
   "source": [
    "### Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYJAG9emTRWW"
   },
   "outputs": [],
   "source": [
    "spike_day0 = data['rate0']\n",
    "emg_day0 = data['EMG0']\n",
    "idx = int((len(spike_day0)//n_steps)*n_steps*0.8)\n",
    "r = len(spike_day0)%n_steps\n",
    "\n",
    "spike_tr = spike_day0[:idx]\n",
    "emg_tr = emg_day0[:idx]\n",
    "spike_te = spike_day0[idx:-r]\n",
    "emg_te = emg_day0[idx:-r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxBH13KzTRWX"
   },
   "source": [
    "### Decoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAvEw2vTTRWY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batches = idx//batch_size\n",
    "gamma_ = np.float32(1.)\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in tqdm_notebook(range(n_epochs)):\n",
    "        spike_gen_obj = utils.get_batches(spike_tr,batch_size)\n",
    "        emg_gen_obj = utils.get_batches(emg_tr,batch_size)\n",
    "        for ii in range(n_batches):\n",
    "            spike_batch = next(spike_gen_obj)\n",
    "            emg_batch = next(emg_gen_obj)\n",
    "            sys.stdout.flush()\n",
    "            sess.run(optimizer,feed_dict={spike:spike_batch,emg:emg_batch,gamma:gamma_})\n",
    "        ae_loss_ = ae_loss.eval(feed_dict={spike:spike_tr,emg:emg_tr,gamma:gamma_})\n",
    "        emg_loss_ = emg_loss.eval(feed_dict={spike:spike_tr,emg:emg_tr,gamma:gamma_})\n",
    "        gamma_ = emg_loss_/ae_loss_\n",
    "        if (epoch % 50 == 0) or (epoch == n_epochs-1): \n",
    "            spike_hat_tr,spike_hat_te = [logits.eval(feed_dict={spike:spike_tr}),logits.eval(feed_dict={spike:spike_te})]\n",
    "            emg_hat_tr,emg_hat_te = [emg_hat.eval(feed_dict={spike:spike_tr,emg:emg_tr}),\n",
    "                                     emg_hat.eval(feed_dict={spike:spike_te,emg:emg_te})]\n",
    "            print(\"Epoch:\", epoch, \"\\tAE_loss:\",ae_loss_, \"\\tEMG_loss:\",emg_loss_)\n",
    "            print(\"AE Train %VAF:\", utils.vaf(spike_tr,spike_hat_tr),\"\\AE Test %VAF:\", utils.vaf(spike_te,spike_hat_te))\n",
    "            print(\"EMG Train %VAF:\", utils.vaf(emg_tr,emg_hat_tr),\"\\EMG Test %VAF:\", utils.vaf(emg_te,emg_hat_te))\n",
    "    saver.save(sess, \"./Models/decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4N__VgiGTRWa"
   },
   "source": [
    "### EMG Predictions (Day-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-Nw6BcPTRWa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t,emg_te[:1200,0],t,emg_hat_te[:1200,0])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('EMG')\n",
    "plt.title('Flexor Carpi Radialis')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t,emg_te[:1200,11],t,emg_hat_te[:1200,11])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('EMG')\n",
    "plt.title('Extensor Carpi Radialis')\n",
    "plt.legend(('Actual','Predicted'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amMm2WrATRWc"
   },
   "source": [
    "## Domain Adaptation\n",
    "![ADAN2](https://github.com/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/img/ADAN2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4RAHVrlTRWc"
   },
   "source": [
    "### ADAN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwlp_BcqTRWd"
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 16\n",
    "d_lr = 0.00001\n",
    "g_lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uK28hzWNTRWe"
   },
   "source": [
    "### ADAN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-9PyfHqTRWg"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(seed=42)\n",
    "\n",
    "g = tf.train.import_meta_graph('./Models/decoder.meta')\n",
    "graph = tf.get_default_graph()\n",
    "spike = graph.get_tensor_by_name(\"spike:0\")\n",
    "emg_hat =  graph.get_tensor_by_name(name=\"emg_hat:0\")\n",
    "\n",
    "input_day0 = tf.placeholder(tf.float32, (None, spike_dim), name='input_day0')\n",
    "input_dayk = tf.placeholder(tf.float32, (None, spike_dim), name='input_dayk')\n",
    "\n",
    "# complete the generator function\n",
    "def generator(input_, reuse=False):\n",
    "    with tf.variable_scope('generator',initializer=tf.initializers.identity(),reuse=reuse):\n",
    "    return output\n",
    "\n",
    "# complete the discriminator function\n",
    "def discriminator(input_, n_units=[64,32,latent_dim], reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
    "        noise = tf.random_normal(tf.shape(input_), dtype=tf.float32)\n",
    "        input_ = input_+noise\n",
    "        return latent, logits\n",
    "\n",
    "input_dayk_aligned = generator(input_dayk)\n",
    "latent_day0,logits_day0 = discriminator(input_day0)\n",
    "latent_dayk,logits_dayk = discriminator(input_dayk_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kg6Rb2AgTRWi"
   },
   "source": [
    "### ADAN Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zuE4TS9TRWi"
   },
   "outputs": [],
   "source": [
    "# finish this\n",
    "d_loss_0 = \n",
    "d_loss_k = \n",
    "d_loss = \n",
    "g_loss =\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "d_opt = \n",
    "g_opt = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VI6uBqLmTRWj"
   },
   "source": [
    "### ADAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TqlkvKATRWk"
   },
   "outputs": [],
   "source": [
    "r = len(data['rate1'])%n_steps\n",
    "spike_dayk = data['rate1'][:-r]\n",
    "emg_dayk = data['EMG1'][:-r] \n",
    "n_batches = min(len(spike_day0),len(spike_dayk))//(batch_size)\n",
    "\n",
    "a_vars = [var.name for var in t_vars if var.name.startswith('autoencoder')]\n",
    "for i,name in enumerate(a_vars):\n",
    "    tf.train.init_from_checkpoint('./Models/', {name[:-2]:d_vars[i]})\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess: \n",
    "        init.run()\n",
    "        g.restore(sess, tf.train.latest_checkpoint('./Models/'))\n",
    "        for epoch in tqdm_notebook(range(n_epochs)):\n",
    "            spike_0_gen_obj = utils.get_batches(spike_day0,batch_size)\n",
    "            spike_k_gen_obj = utils.get_batches(spike_dayk,batch_size)\n",
    "            for ii in range(n_batches):\n",
    "                spike_0_batch = next(spike_0_gen_obj)\n",
    "                spike_k_batch = next(spike_k_gen_obj)\n",
    "                sys.stdout.flush()\n",
    "                _,g_loss_ = sess.run([g_opt,g_loss],feed_dict={input_day0:spike_0_batch,input_dayk:spike_k_batch})\n",
    "                _,d_loss_0_,d_loss_k_ = sess.run([d_opt,d_loss_0,d_loss_k],feed_dict={input_day0:spike_0_batch,input_dayk:spike_k_batch})\n",
    "            if (epoch % 10 == 0) or (epoch == n_epochs-1):\n",
    "                print(\"\\r{}\".format(epoch), \"Discriminator loss_day_0:\",d_loss_0_,\"\\Discriminator loss_day_k:\",d_loss_k_)\n",
    "                input_dayk_aligned_ = input_dayk_aligned.eval(feed_dict={input_dayk:spike_dayk})\n",
    "                emg_dayk_aligned = emg_hat.eval(feed_dict={spike:input_dayk_aligned_})\n",
    "                emg_k_ = emg_hat.eval(feed_dict={spike:spike_dayk})\n",
    "                print(\"EMG non-aligned VAF:\", utils.vaf(emg_dayk,emg_k_),\"\\tEMG aligned VAF:\", utils.vaf(emg_dayk,emg_dayk_aligned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0BpkODqTRWl"
   },
   "source": [
    "### EMG Predictions (Day-16) Before & After Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RT1Wgzy3TRWm"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t,emg_dayk[:1200,0],t,emg_k_[:1200,0],t,emg_dayk_aligned[:1200,0])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('EMG')\n",
    "plt.title('Flexor Carpi Radialis')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t,emg_dayk[:1200,11],t,emg_k_[:1200,11],t,emg_dayk_aligned[:1200,11])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('EMG')\n",
    "plt.title('Extensor Carpi Radialis')\n",
    "plt.legend(('Actual','Non-Aligned','Aligned'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "07_Main_Exercise.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
