{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuhA6Sl3-0w-"
   },
   "source": [
    "# Introduction to Shallow Linear Machine Learning\n",
    "This notebook is part of the [SachsLab Workshop for Intracranial Neurophysiology and Deep Learning](https://github.com/SachsLab/IntracranialNeurophysDL).\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/02_01_basic_lda.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/02_01_basic_lda.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3cZA3P-bFM4"
   },
   "source": [
    "### Normalize Environments\n",
    "Run the first two cells to normalize Local / Colab environments, then proceed below for the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "C71up2w1-0xA",
    "outputId": "618499e9-a857-416f-c12b-b1a583f002a9",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standard block to equalize local and Colab.\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    from google.colab import files\n",
    "    os.chdir('..')\n",
    "    \n",
    "    if not (Path.cwd() / '.kaggle').is_dir():\n",
    "        # Configure kaggle\n",
    "        uploaded = files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
    "        if 'kaggle.json' in uploaded.keys():\n",
    "            !mkdir -p ~/.kaggle\n",
    "            !mv kaggle.json ~/.kaggle/\n",
    "            !chmod 600 ~/.kaggle/kaggle.json\n",
    "        \n",
    "    if not (Path.cwd() / 'IntracranialNeurophysDL').is_dir():\n",
    "        # Download the workshop repo and change to its directory\n",
    "        !git clone --recursive https://github.com/SachsLab/IntracranialNeurophysDL.git\n",
    "        os.chdir('IntracranialNeurophysDL')\n",
    "    \n",
    "    !pip install -q kaggle\n",
    "    plt.style.use('dark_background')\n",
    "    IN_COLAB = True\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    if Path.cwd().stem == 'notebooks':\n",
    "        os.chdir(Path.cwd().parent)\n",
    "    # Make sure the kaggle executable is on the PATH\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
    "    IN_COLAB = False\n",
    "    \n",
    "from indl import turbo_cmap\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 24,\n",
    "    'axes.labelsize': 20,\n",
    "    'lines.linewidth': 3,\n",
    "    'lines.markersize': 10,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "Ox4PmsAh-0xD",
    "outputId": "a3b61272-0f79-43eb-eaf4-d1019da94666",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download faces_basic if we don't already have it.    \n",
    "datadir = Path.cwd() / 'data' / 'kjm_ecog'\n",
    "if not (datadir / 'converted').is_dir():\n",
    "    !kaggle datasets download --unzip --path {str(datadir / 'converted' / 'faces_basic')} cboulay/kjm-ecog-faces-basic\n",
    "    print(\"Finished downloading and extracting data.\")\n",
    "else:\n",
    "    print(\"Data directory found. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iw8igvIc-0xF"
   },
   "source": [
    "Let's say we have a trivial system of linear equations:\n",
    "\n",
    "\\begin{array}{lcl}\n",
    "1w_0 + 1w_1 & = & 35\\\\\n",
    "2w_0 + 4w_1 & = & 94\n",
    "\\end{array}\n",
    "\n",
    "This system can be represented in matrix notation, where\n",
    "\n",
    "$X=\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "1 & 4 \\\\\n",
    "\\end{bmatrix}, \n",
    "w=\\begin{bmatrix}\n",
    "w_0 & w_1 \\\\\n",
    "\\end{bmatrix}, \n",
    "y=\\begin{bmatrix}\n",
    "35 & 94 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "w_0 & w_1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "1 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "35 & 94 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$wX=y$\n",
    "\n",
    "Let's let w and y be matrices:\n",
    "\n",
    "$WX=Y$\n",
    "\n",
    "These variables can take on different meanings depending on the\n",
    "experiment formulation and type of analysis. This can be confusing.\n",
    "Instead, let's be consistent about how the variable names map to our data, and then\n",
    "we will shuffle the equation around as needed.\n",
    "\n",
    "X: Known brain signals, often reshaped into a matrix.\n",
    "\n",
    "Y: Known labels (intention, behaviour, experimental conditions).\n",
    "\n",
    "W: The unknown variable (weights and biases).\n",
    "\n",
    "| X dim | Exp. Type | Equation &nbsp;&nbsp;&nbsp;&nbsp;| Y | W | \n",
    "|---|---|---|---|---| \n",
    "|space, time, trials|BCI|$WX=Y$|Intention/Behav.|Decoder|\n",
    "|space, time, trials|Stats|$WY=X$|Task Cond.|Encoder|\n",
    "|space, trials|BCI|$WX=Y$|Intention/Behav.|Spatial filter|\n",
    "|space, trials|Stats|$WY=X$|Task Cond.|Spatial patterns|\n",
    "\n",
    "---\n",
    "**Bonus** \n",
    "\n",
    "$\\begin{array}\\\\\n",
    "WX&=&Y \\\\\n",
    "W^{-1}WX&=&W^{-1}Y \\\\\n",
    "X&=&W^{-1}Y\\end{array}$\n",
    "\n",
    "Or, in other words, the Decoder matrix is the inverse of the Encoder matrix.\n",
    "See [Haufe et al., NeuroImage 2014](https://www.sciencedirect.com/science/article/pii/S1053811913010914)\n",
    "\n",
    "---\n",
    "\n",
    "Let's solve for W\n",
    "\n",
    "$\\begin{array}\\\\\n",
    "WX&=&Y \\\\\n",
    "WXX^{-1}&=&YX^{-1} \\\\\n",
    "W&=&YX^{-1}\\end{array}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "TVQjJTtJ-0xG",
    "outputId": "57ac8044-d098-41c5-926d-b6ebc3e564e4",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 2,], [1, 4]])\n",
    "Y = np.array([[35, 94]])\n",
    "\n",
    "# Task: Calculate the inverse of X\n",
    "X_inv = np.linalg.inv(X)\n",
    "\n",
    "# Task: Calculate W\n",
    "W = Y @ X_inv  # or np.matmul(Y, X_inv)\n",
    "\n",
    "print(W.shape, Y.shape, X.shape)\n",
    "print(\"1*{} + 1*{} = 35; {}\".format(\n",
    "    W[0, 0], W[0, 1], 1 * W[0, 0] + 1 * W[0, 1] == 35))\n",
    "print(\"2*{} + 4*{} = 94; {}\".format(\n",
    "    W[0, 0], W[0, 1], 2 * W[0, 0] + 4 * W[0, 1] == 94))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkUoHU2r-0xK"
   },
   "source": [
    "The majority of brain signal analysis is getting the data into these variables (X, Y),\n",
    "and then solving this equation, often with different constraints imposed on the solution.\n",
    "\n",
    "Let's look at one of the most basic examples... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wPu8w9UPWYhw"
   },
   "source": [
    "# (Fisher's) Linear Discriminant Analysis (LDA)\n",
    "\n",
    "Using the BCI formulation (WX=Y), find the transformation matrix (W) that\n",
    "maximizes the between-class variance in X relative to the within-class variance in X,\n",
    "where \"class\" is encoded in Y.\n",
    "\n",
    "Note that in the below example, X shape is (trials, features). This requires that X be transposed prior to left-multiplying by W of shape (out_features, in_features). i.e. $Y = WX^T$. The ML library will typically be explicit about whether it wants repetitions (trials) to be in the first dimension or last dimension, and the library will handle transposing and/or right- vs left-multiplying weights as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_omnHF-tWaDH"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MDQviZlg-0xL",
    "outputId": "1c216f5d-2a74-4aa5-baee-c172b16eb4f3",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from one participant.\n",
    "from data.utils.fileio import from_neuropype_h5\n",
    "\n",
    "SUB_ID = 'de'\n",
    "\n",
    "test_file = datadir / 'converted' / 'faces_basic' / (SUB_ID + '_bp.h5')\n",
    "chunks = from_neuropype_h5(test_file)\n",
    "chunk_names = [_[0] for _ in chunks]\n",
    "chunk = chunks[chunk_names.index('signals')][1]\n",
    "ax_types = [_['type'] for _ in chunk['axes']]\n",
    "instance_axis = chunk['axes'][ax_types.index('instance')]\n",
    "n_trials, n_timepoints, n_channels = chunk['data'].shape\n",
    "X = chunk['data'].reshape((n_trials, n_timepoints*n_channels))  # 603 trials x 527 features\n",
    "Y = instance_axis['data']['Marker'].values\n",
    "\n",
    "print(\"Data shape was {} trials x {} timepoints x {} channels\".format(\n",
    "    n_trials, n_timepoints, n_channels))\n",
    "print(\"X shape: {}; Y shape: {}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PoosxKdWce5"
   },
   "source": [
    "## Plot individual trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "JQrlR07S-0xO",
    "outputId": "8e88566c-b5e7-454b-cc16-b0ea4c16d436",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8), facecolor='white')\n",
    "\n",
    "N_PLOT_CHANS = 3\n",
    "N_PLOT_TRIALS = 10\n",
    "uq_Y = np.unique(Y)\n",
    "plot_chans = np.random.randint(0, n_channels, N_PLOT_CHANS)\n",
    "for y_ix, y_val in enumerate(uq_Y):\n",
    "    rand_subset = np.where(Y == y_val)[0]\n",
    "    np.random.shuffle(rand_subset)  # Note that `shuffle` operates on data in place\n",
    "    for ch_ix, chan_id in enumerate(plot_chans):\n",
    "        plt.subplot(len(uq_Y), len(plot_chans), y_ix * len(plot_chans) + ch_ix + 1)\n",
    "        plt.plot(chunk['data'][rand_subset[:N_PLOT_TRIALS], :, chan_id].T)\n",
    "        if ch_ix == 0:\n",
    "            plt.ylabel(y_val)\n",
    "        if y_ix == 0:\n",
    "            plt.title(\"Channel {}\".format(chan_id))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrp0AHXWWgAt"
   },
   "source": [
    "## Plot condition-averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "ac6UOnHCRIyk",
    "outputId": "4005908c-51bd-44b5-8554-f76f692d1bca"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8), facecolor='white')\n",
    "for ch_ix, chan_id in enumerate(plot_chans):\n",
    "    plt.subplot(1, len(plot_chans), ch_ix + 1)\n",
    "    for y_ix, y_val in enumerate(uq_Y):\n",
    "        cond_trials = np.where(Y == y_val)[0]\n",
    "        _dat = np.mean(chunk['data'][cond_trials, :, chan_id], axis=0)\n",
    "        plt.plot(_dat, label=y_val, linewidth=3)\n",
    "    plt.title(\"Channel {}\".format(chan_id))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rU39MBtu-0xQ"
   },
   "source": [
    "## Perform LDA\n",
    "For a full step-by-step example of doing LDA from scratch, try [this online example](https://www.python-course.eu/linear_discriminant_analysis.php).\n",
    "\n",
    "Here, let's try to classify these data using simple / shallow machine learning using the excellent scikit-learn Python package.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/lda_qda.html\n",
    "\n",
    "Note the LDA initialization argument `shrinkage=auto`. This is a form of regularization. While the exact type of regularization used here is out of scope of the workshop, refer to the sklearn page for more info.\n",
    "[Link](https://scikit-learn.org/stable/auto_examples/classification/plot_lda.html#sphx-glr-auto-examples-classification-plot-lda-py)\n",
    "\n",
    "![alt text](https://scikit-learn.org/stable/_images/sphx_glr_plot_lda_001.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Cl8jmqTQ-0xQ",
    "outputId": "276046a3-b9bd-458c-d6f5-7c26d00eaf68",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "lda = LDA(shrinkage='auto', solver='eigen')\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "y_preds = []\n",
    "y_true = []\n",
    "for trn, tst in splitter.split(X, Y):\n",
    "    lda.fit(X[trn], Y[trn])\n",
    "    y_preds.append(lda.predict(X[tst]))\n",
    "    y_true.append(Y[tst])\n",
    "\n",
    "y_preds = np.hstack(y_preds)\n",
    "y_true = np.hstack(y_true)\n",
    "\n",
    "pcnt_corr = 100 * np.sum(y_preds == y_true) / len(y_preds)\n",
    "print(\"3-class accuracy: {}\".format(pcnt_corr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5gaxHnx-0xU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compare accuracy to baseline accuracy\n",
    "This accuracy seems pretty good, but it's hard to know how good without knowing what\n",
    "we should expect for baseline accuracy. There are a couple ways to do this.\n",
    "First, we will shuffle our labels and try again.\n",
    "Second, we will simply say that every trial is ISI and see how we do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hDf3IcqP-0xV",
    "outputId": "67c33272-f185-40f0-8b0c-7dc33f08ed70",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuff_preds = []\n",
    "y_shuff = []\n",
    "Y_shuff = np.copy(Y)\n",
    "np.random.shuffle(Y_shuff)\n",
    "for trn, tst in splitter.split(X, Y_shuff):\n",
    "    lda.fit(X[trn], Y_shuff[trn])\n",
    "    shuff_preds.append(lda.predict(X[tst]))\n",
    "    y_shuff.append(Y[tst])\n",
    "\n",
    "shuff_preds = np.hstack(shuff_preds)\n",
    "y_shuff = np.hstack(y_shuff)\n",
    "\n",
    "pcnt_corr = 100 * np.sum(shuff_preds == y_shuff) / len(y_preds)\n",
    "print(\"3-class shuffled accuracy: {}\".format(pcnt_corr))\n",
    "\n",
    "y_always_ISI = np.array(['ISI']*len(y_shuff))\n",
    "pcnt_corr = 100 * np.sum(y_always_ISI == y_true) / len(y_true)\n",
    "print(\"Always-ISI accuracy: {}\".format(pcnt_corr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKuBCWjT-0xY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Confusion Matrix\n",
    "So the best we can do with random guessing is in the 35-40% range.\n",
    "The best we can do by guessing always ISI is 50% (note: this is technically \"better than chance\",\n",
    "so \"better than chance\" is meaningless!). This kind of check is very important when the data are not balanced. Imagine a model intended to identify rare diseases; if the model rule was \"always False\" it might still be 99.99% accurate!\n",
    "\n",
    "One way to get a good feeling for how your errors are distributed is by plotting a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "ny-nK6eR-0xZ",
    "outputId": "d28490eb-66e7-4177-c12e-723a6b0a13fe",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "classes = unique_labels(y_true, y_preds)\n",
    "cm_int = np.copy(cm)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
    "fig, ax = plt.subplots(figsize=(8, 8), facecolor='white')\n",
    "im = ax.imshow(cm, interpolation='nearest')\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "# We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "      yticks=np.arange(cm.shape[0]),\n",
    "      # ... and label them with the respective list entries\n",
    "      xticklabels=classes, yticklabels=classes,\n",
    "      ylabel='True label',\n",
    "      xlabel='Predicted label')\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm_int[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXbSAnXR-0xe"
   },
   "source": [
    "This is a pretty good result. But remember, we did some significant preprocessing based on years\n",
    "of expertise working with these types of data.\n",
    "Also, we used ~540 within-session trials to train the classifier.\n",
    "This classifier will not generalize well to another patient,\n",
    "and maybe not even to another session with the same patient.\n",
    "No one wants to spend 540 trials training a keyboard before they start typing every day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxtV1AdXXtGd"
   },
   "source": [
    "## Visualize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "lC-5dw-6Y6oP",
    "outputId": "7c3fc908-c20c-4ddb-9b0e-cbb3b6a93b37"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8), facecolor='white')\n",
    "coefs = lda.coef_.reshape(3, n_timepoints, n_channels)\n",
    "for y_ix, y_val in enumerate(uq_Y):\n",
    "    plt.subplot(2, 3, y_ix + 1)\n",
    "    plt.imshow(coefs[y_ix].T, cmap=turbo_cmap)\n",
    "    plt.title(y_val)\n",
    "    plt.xlabel('timepoints')\n",
    "    plt.ylabel('channels')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "width = 0.25\n",
    "rms_coefs = np.sqrt(np.mean(coefs**2, axis=1))\n",
    "for y_ix, y_val in enumerate(uq_Y):\n",
    "    plt.bar(np.arange(n_channels) + y_ix*width, rms_coefs[y_ix], width, label=y_val)\n",
    "plt.legend()\n",
    "\n",
    "# TODO: Scatterplot per-class weights using electrode locations for x and y.\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7rew1vMFtfn"
   },
   "source": [
    "Resume Part 2 slides."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "02_01_basic_lda.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
