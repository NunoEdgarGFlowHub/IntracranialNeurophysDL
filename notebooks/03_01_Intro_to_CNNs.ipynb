{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIrqahR6xb_F"
   },
   "source": [
    "# Introduction to Convolutional Neural Networks\n",
    "This notebook is part of the [SachsLab Workshop for Intracranial Neurophysiology and Deep Learning](https://github.com/SachsLab/IntracranialNeurophysDL).\n",
    "\n",
    "### Normalize Environments\n",
    "Run the first cell to setup our environment and normalize local/Colab environments,\n",
    "then proceed to follow the lesson below.\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/03_01_Intro_to_CNNs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/03_01_Intro_to_CNNs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "MZlLwbI_xb_H",
    "outputId": "f65b9cb5-e646-4b03-c9e2-2b6f24a45932",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize local and Colab.\n",
    "try:\n",
    "    # See if we are running on google.colab\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "    # Setup tensorflow 2.0\n",
    "    !pip install -q tensorflow-gpu==2.0.0-rc0\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIqAhEWgxb_K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1-D Convolutional Layers\n",
    "The highest-profile application of deep learning is machine vision. The most popular type of network\n",
    "in machine vision is a Convolutional Neural Network (CNN). As such, there are many, MANY wonderful\n",
    "tutorials about CNNs free on the internet. If you have trouble following this section then please take\n",
    "a moment to read through one or two CNN tutorials.\n",
    "\n",
    "Before continuing, it's worth mentioning that CNNs were inspired by how the brain processes vision,\n",
    "and researchers are using CNNs to develop models of vision that they then test with neural data.\n",
    "We will talk more about that in a later session.\n",
    "\n",
    "In image processing, you ALWAYS expect a car window to be physically higher than the tires,\n",
    "so the 2-D spatial information is important for classification. In multi-channel neural data, however,\n",
    "there is no reason to think that a channel carrying house-related information will ALWAYS precede a channel\n",
    "with face-related information, so channel-order is not useful in a general model.\n",
    "(Side note: channel order may be useful if channels are mapped to their physical locations in a normalized template space but that is out of scope.)\n",
    "What is useful in neural data is the temporal relationship between samples.\n",
    "While most vision-related CNNs use 2-D convolutions (or 3-D in colour images), here we are using 1-D convolutions.\n",
    "\n",
    "[Here is a nice article](https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf)\n",
    "on 1-D convolutions, and it has some good links and references at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeOlMCw2OeJQ"
   },
   "source": [
    "### 1-D Convolution as an FIR Filter in Scipy\n",
    "A convolution sweeps a 'kernel' across a dataset, at each step multiplying each value in the kernel with the \n",
    "underlying sample, then outputting the sum of the products. This is exactly the same as FIR filtering.\n",
    "\n",
    "Next we create a 35-45 Hz bandpass FIR filter and apply it to a test signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yKIrE6rIxb_L",
    "outputId": "84c063e5-d967-4db4-c4c6-85cb5b5df683",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "fs = 200.0            # samples per second\n",
    "dur = 1.0             # duration in seconds\n",
    "freqs = [15.0, 40.0]  # Peak frequencies, in Hz\n",
    "amps = [2.0, 1.0]     # Sinusoidal component amplitudes\n",
    "gstop = 65            # The minimum attenuation in the stopband (dB).\n",
    "bandwidth = 5         # Width of the filter transition region.\n",
    "filt_cuts = [35, 45]  # Filter corner frequencies (Hz)\n",
    "\n",
    "nyq = 0.5 * fs\n",
    "n_samples = int(dur * fs)\n",
    "t = np.arange(n_samples) / fs  # Timestamp vector\n",
    "\n",
    "# Create a filter\n",
    "# https://scipy-cookbook.readthedocs.io/items/FIRFilter.html\n",
    "N, beta = scipy.signal.kaiserord(gstop, bandwidth / nyq)\n",
    "print(N)\n",
    "atten = scipy.signal.kaiser_atten(N, bandwidth / nyq)\n",
    "beta2 = scipy.signal.kaiser_beta(atten)\n",
    "taps = scipy.signal.firwin(N, filt_cuts, nyq=nyq, pass_zero=False, window=('kaiser', beta), scale=False)\n",
    "w, h = scipy.signal.freqz(taps, 1.0, worN=2000)  # frequency response\n",
    "\n",
    "# Create an impulse signal, and a filtered copy of it\n",
    "impulse = np.zeros_like(t)\n",
    "impulse[int(n_samples//2)] = 1.0\n",
    "imp_filt = scipy.signal.lfilter(taps, 1.0, impulse)\n",
    "imp_conv = scipy.signal.convolve(impulse, taps, 'same')\n",
    "# lfilter vs convolve considerations: https://scipy-cookbook.readthedocs.io/items/ApplyFIRFilter.html\n",
    "\n",
    "# Create a signal: sum of sinusoids\n",
    "x = amps[0] * np.sin(2*np.pi*freqs[0]*t) + amps[1] * np.sin(2*np.pi*freqs[1]*t)\n",
    "x_filt = scipy.signal.lfilter(taps, 1.0, x)\n",
    "x_conv = scipy.signal.convolve(x, taps, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "colab_type": "code",
    "id": "EjfkLYBDxb_N",
    "outputId": "6cd1e96c-6bc2-4823-b2f8-8cb65c3ce09e",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Describe the filter\n",
    "plt.figure(figsize=(12, 6), facecolor='white')\n",
    "# Plot filter coefficients\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(np.arange(len(taps)) / fs, taps, 'b')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('b', color='b')\n",
    "plt.title('Filter Coefficients')\n",
    "# Frequency response\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot((fs * 0.5 / np.pi) * w, abs(h))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.title('Frequency Response')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot signals and filtered results\n",
    "plt.figure(figsize=(12, 6), facecolor='white')\n",
    "# Impulse\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(t, impulse, 'b', label='input')\n",
    "plt.plot(t, imp_filt, 'r', label='lfilter')\n",
    "plt.plot(t, imp_conv, 'k', label='convolve')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Impulse Response')\n",
    "# Plot signal and filtered signal\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t, x, 'b')\n",
    "plt.plot(t, x_filt, 'r')\n",
    "plt.plot(t, x_conv, 'k')\n",
    "plt.title('Signal and Filtered Signal')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hbGJXtZxb_R",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1-D Convolution as an FIR Filter in Keras\n",
    "Let's create a NN model with a single 1-D convolution layer.\n",
    "Then in the next cell we will \"train\" our model using the above filter coefficients,\n",
    "and apply the model to our signal, and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "vEBwU3mwxb_S",
    "outputId": "7cb979ba-960d-450b-8ccb-411eff7efca0",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(1, N, padding='same', activation='linear', input_shape=(n_samples, 1)))\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJQctRMpOmLs"
   },
   "source": [
    "### Create a CNN model that does FIR filtering\n",
    "We will \"train\" the model by setting the weights directly with the filter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "Qigkfku1xb_U",
    "outputId": "af2a12ce-ead7-4a2a-88e4-e3a40028a7a0",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# \"Train\" our model with FIR filter weights\n",
    "model.layers[0].set_weights([taps.reshape(N, 1, 1), np.array([0])])  # (filter, bias)\n",
    "# Make sure they took; get the weights back and compare them\n",
    "temp = model.layers[0].get_weights()[0].reshape(-1,)\n",
    "assert(np.allclose(taps, temp))  # Close enough. Slightly different due to lower precision (tf 32-bit vs scipy 64-bit)\n",
    "# Apply the model to our signal and visualize the output\n",
    "x_cnn = model.predict(x.reshape(-1, 1)[None,])\n",
    "plt.figure(figsize=(6, 4), facecolor='white')\n",
    "plt.plot(t, x, 'b', label='input')\n",
    "plt.plot(t, x_cnn.reshape(-1,), 'r', label='CNN output')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wjrAeNhxb_X",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As expected, the NN model filtered out the 15 Hz signal leaving only the 40 Hz signal. Way to ~~go~~ over-engineer! Notice that the filtered signal is tapered at the edges. This is because our model uses `padding='same'`, which pads the input with zeros so the output is the same size as the input. If we didn't, our output would only include the middle 40 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbB9n0ZFPIZk"
   },
   "source": [
    "### Train CNN to filter data\n",
    "Let's go a little crazy. Let's learn a Conv1D layer from scratch that filters for us.\n",
    "Train a Conv1D model that takes as input the 2-sinusoid signal and is optimized to output the 1-sinusoid signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "hTpnQ8mTxb_Y",
    "outputId": "7880ba3b-ec51-40db-def2-2d0af37a9b66",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create our data\n",
    "N = 160\n",
    "n_trials = 2000\n",
    "batch_size = 5\n",
    "n_epochs = 5\n",
    "n_channels = 1\n",
    "n_samples = len(t)\n",
    "X = []\n",
    "Y = []\n",
    "for tr_idx in range(n_trials):\n",
    "    t_offset = t + np.random.rand(1) / 15  # shift timestamps by up to 1/15th of a second\n",
    "    y = amps[1] * np.sin(2*np.pi*freqs[1]*t_offset)\n",
    "    x = amps[0] * np.sin(2*np.pi*freqs[0]*t_offset) + y\n",
    "#     x += 0.5 * np.random.randn(*x.shape)  # Uncomment to add noise\n",
    "    Y.append(y.reshape(n_samples, n_channels).astype(np.float32))\n",
    "    X.append(x.reshape(n_samples, n_channels).astype(np.float32))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "dataset = dataset.shuffle(n_trials).batch(batch_size).repeat()\n",
    "# Recreate the above model (to reset its weights)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(1, N, padding='same', activation='linear', input_shape=(n_samples, n_channels)))\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "# Train\n",
    "history = model.fit(x=dataset, epochs=n_epochs, steps_per_epoch=n_trials // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "colab_type": "code",
    "id": "QmskXivqxb_a",
    "outputId": "84bc092e-a372-402c-e8e5-c63e590fe736",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coefs = model.layers[0].get_weights()[0].reshape(-1, 1)\n",
    "w, h = scipy.signal.freqz(coefs, 1.0, worN=2000)  # frequency response\n",
    "\n",
    "# Plot filter design\n",
    "plt.figure(figsize=(12, 6), facecolor='white')\n",
    "# Filter coefficients\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(np.arange(len(coefs)) / fs, coefs, 'b')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('b', color='b')\n",
    "plt.title('Filter Coefficients')\n",
    "# Frequency response\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot((fs * 0.5 / np.pi) * w, abs(h))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.title('Frequency Response')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot signals\n",
    "plt.figure(figsize=(6, 6), facecolor='white')\n",
    "y = amps[1] * np.sin(2*np.pi*freqs[1]*t)\n",
    "x = amps[0] * np.sin(2*np.pi*freqs[0]*t) + y\n",
    "x_cnn = model.predict(x.reshape(-1, 1)[None,])\n",
    "plt.plot(t, x, 'b', label='input')\n",
    "plt.plot(t, y, 'k', label='target')\n",
    "plt.plot(t, x_cnn.reshape(-1,), 'r', label='CNN output')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim([0, 0.1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywspPdrMxb_d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The reconstruction is pretty good. Notice that the frequency response in the high-frequencies is large.\n",
    "This is because there is essentially no penalty for allowing high-frequencies through as our signals have no high-frequency content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGCOKLrSPsPi"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Go back above 2 cells to when the model was trained and uncomment the line to add noise, then run the cells again. If you are really eager / bored, then you could try removing the padding option from the Conv1D layer, but don't forget to also slice the y-arrays before adding them to the Y list ([N:-N], I think, there might be a +1 or -1 in there).\n",
    "\n",
    "If instead of trying to reconstruct a signal, our (deep) model is trying to decode a brain state, and one or more layers in the deep model are convolutional layers, then the model might learn filters with passbands that are optimal for the task."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "03_01_Intro_to_CNNs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
