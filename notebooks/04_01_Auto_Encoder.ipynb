{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auto-Encoder",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/04_01_Auto_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBeAkaTlHi-9",
        "colab_type": "text"
      },
      "source": [
        "# Auto-Encoder to process spike waveforms\n",
        "\n",
        "This notebook is part of the [SachsLab Workshop for Intracranial Neurophysiology and Deep Learning](https://github.com/SachsLab/IntracranialNeurophysDL).\n",
        "\n",
        "Run the first two cells to normalize Local / Colab environments, then proceed below for the lesson.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMqIpetxHPxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORzJBw94H8I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "try:\n",
        "    # See if we are running on google.colab\n",
        "    import google.colab\n",
        "    from google.colab import files\n",
        "    os.chdir('..')\n",
        "    if not (Path.home() / '.kaggle').is_dir():\n",
        "        # Configure kaggle\n",
        "        files.upload()  # Find the kaggle.json file in your ~/.kaggle directory.\n",
        "        !pip install -q kaggle\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !mv kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "    if Path.cwd().stem != 'IntracranialNeurophysDL':\n",
        "        if not (Path.cwd() / 'IntracranialNeurophysDL').is_dir():\n",
        "            # Download the workshop repo and change to its directory\n",
        "            !git clone --recursive https://github.com/SachsLab/IntracranialNeurophysDL.git\n",
        "        os.chdir('IntracranialNeurophysDL')\n",
        "    IN_COLAB = True\n",
        "    # Setup tensorflow 2.0\n",
        "    !pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "except ModuleNotFoundError:\n",
        "    IN_COLAB = False\n",
        "    import sys\n",
        "    if Path.cwd().stem == 'notebooks':\n",
        "        os.chdir(Path.cwd().parent)\n",
        "    # Make sure the kaggle executable is on the PATH\n",
        "    os.environ['PATH'] = os.environ['PATH'] + ';' + str(Path(sys.executable).parent / 'Scripts')\n",
        "\n",
        "# Try to clear any logs from previous runs\n",
        "if (Path.cwd() / 'logs').is_dir():\n",
        "    import shutil\n",
        "    try:\n",
        "        shutil.rmtree(str(Path.cwd() / 'logs'))\n",
        "    except PermissionError:\n",
        "        print(\"Unable to remove logs directory.\")\n",
        "\n",
        "# Additional imports\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from indl import enable_plotly_in_cell\n",
        "%load_ext tensorboard.notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUJxpGCVI8NQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip data\n",
        "datadir = Path.cwd() / 'data' / 'vae_wf'\n",
        "if not (datadir / 'converted').is_dir():\n",
        "    !kaggle datasets download -d guilmer/primate-pfc-spike-waveforms \n",
        "    print(\"Finished downloading. Now extracting contents...\")\n",
        "    data_path = Path('primate-pfc-spike-waveforms.zip')\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(datadir)\n",
        "    data_path.unlink()\n",
        "    print(\"Finished extracting data.\")\n",
        "else:\n",
        "    print(\"Data directory found. Skipping download.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnO3pHZ4Jgtq",
        "colab_type": "text"
      },
      "source": [
        "## Load data and plot a few examples to see what we're up against. \n",
        "\n",
        "This data was recorded from a 96 channel Utah Array in the lateral prefrontal cortex of a macaque monkey. \n",
        "\n",
        "Each channel was manually thresholded to remove invalid channels and to try to obtain the best isolated waveforms. \n",
        "\n",
        "Each waveform is 48 samples long, sampled  @ 30kHz for a duration of 1.6 ms. \n",
        "\n",
        "The data might still contain artefacts and some invalid waveforms.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm_H6jIXLi1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data, convert to float-32 and add extra dim for tensorflow convolution layers\n",
        "wf = np.load(os.path.join(datadir, 'waveforms.npy')).astype(np.float32)\n",
        "wf = wf.reshape(wf.shape[0], wf.shape[1], 1)\n",
        "\n",
        "# Plot 100 randomly selected waveforms\n",
        "n_to_plot = 100\n",
        "plt.figure(facecolor='white')\n",
        "plt.plot(wf[np.random.randint(0, wf.shape[0], n_to_plot),:, 0].T)\n",
        "plt.title(str(n_to_plot) + ' waveforms from ' + str(wf.shape[0]) + ' total');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa0AQ1n7PPZv",
        "colab_type": "text"
      },
      "source": [
        "## De-noising AE\n",
        "\n",
        "In the previous session (03_01_Intro_to_CNNs.ipynb) we implemented a FIR filter from a convolution layer, and we added some noise to our input in order to get proper response in the high frequencies. In other words we modelled: \n",
        "\n",
        "$X + noise \\rightarrow \\hat{X}$\n",
        "\n",
        "where $X$ is our input and $\\hat{X}$ is our output, reconstructing the input minus the noise. This is a good example of a **de-noising AE**.\n",
        "\n",
        "Let's implement another one to see it in more details. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPtJyYRYS6yH",
        "colab_type": "text"
      },
      "source": [
        "### Data pre-processing for deep learning\n",
        "\n",
        "It's always a good idea to normalize your data in some way to restrict it's range roughly around $\\pm 1$. \n",
        "\n",
        "We'll z-score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlj2AH0ULye5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Z-scoring the data\n",
        "wf_mean = np.mean(wf)\n",
        "wf_sd = np.std(wf)\n",
        "\n",
        "z_wf = (wf-wf_mean) / wf_sd\n",
        "\n",
        "plt.figure(facecolor='white', figsize=(20,5))\n",
        "plt.subplot(131)\n",
        "plt.plot(wf[::30000,:,0].T)\n",
        "plt.title('Raw waveforms')\n",
        "plt.subplot(132)\n",
        "plt.plot(z_wf[::30000,:,0].T)\n",
        "plt.title('Z-scored waveforms')\n",
        "plt.subplot(133)\n",
        "plt.plot((z_wf[::30000,:,0] + np.random.randn(z_wf[::30000,:,0].shape[0], z_wf[::30000,:,0].shape[1])).T)\n",
        "plt.title('Z-scored waveforms + noise');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdN10LAVWXI0",
        "colab_type": "text"
      },
      "source": [
        "Even if we are not classifying the data, we need a validation set to make sure we are not over-fitting. We'll use 10000 randomly selected waveforms. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQKSW9DKVE-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Validation set creation\n",
        "n_test_waveforms = 10000\n",
        "valid_idx = np.random.randint(0, z_wf.shape[0], n_test_waveforms)\n",
        "valid_set = z_wf[valid_idx,:,:]\n",
        "\n",
        "# Take only 50 000 waveforms to speed up training\n",
        "n_train_waveforms = 50000\n",
        "train_set = np.delete(z_wf, valid_idx, axis=0)\n",
        "train_set = train_set[np.random.randint(0,train_set.shape[0], n_train_waveforms),:,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEJAipVnYRG0",
        "colab_type": "text"
      },
      "source": [
        "### Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdQkxLuCaurE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model definition\n",
        "# Fully annotated in VAE_SS_Validation notebook\n",
        "# Data augmentation has been left out for now. \n",
        "class betaCVAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim=2, beta=0., learning_rate=1e-2, capacity=0.):  # beta set to 1. is a default VAE\n",
        "\n",
        "    super(betaCVAE, self).__init__()\n",
        "\n",
        "    self.latent_dim = latent_dim\n",
        "    self.beta = beta\n",
        "    self.learning_rate = learning_rate\n",
        "    self.capacity = capacity\n",
        "    \n",
        "    if self.beta > 0.:\n",
        "      self.is_VAE = True\n",
        "    else:\n",
        "      self.is_VAE = False\n",
        "\n",
        "    self.inference_net = tf.keras.Sequential(\n",
        "          [\n",
        "          tf.keras.layers.InputLayer(input_shape=(48, 1)),\n",
        "          tf.keras.layers.Conv1D(filters=25, kernel_size=5, strides=1, activation=tf.nn.elu, padding='same'),  # output => 48 x 25\n",
        "          tf.keras.layers.MaxPool1D(pool_size=2),  # output => 24 x 25\n",
        "          tf.keras.layers.Conv1D(filters=25, kernel_size=3, strides=1, activation=tf.nn.elu, padding='same'),  # output => 24 x 25\n",
        "          tf.keras.layers.MaxPool1D(pool_size=2),  # output => 12 x 25    \n",
        "          tf.keras.layers.Conv1D(filters=25, kernel_size=3, strides=1, activation=tf.nn.elu, padding='same'),  # output => 12 x 25\n",
        "          tf.keras.layers.MaxPool1D(pool_size=2),  # output => 6 x 25\n",
        "          tf.keras.layers.Flatten(),  # 150 x 1\n",
        "          tf.keras.layers.Dense(50, activation=tf.nn.elu), # 100 x 1\n",
        "          tf.keras.layers.Dense(latent_dim + latent_dim)\n",
        "          ]\n",
        "      )\n",
        "\n",
        "\n",
        "    self.generative_net = tf.keras.Sequential(\n",
        "          [\n",
        "          tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "          tf.keras.layers.Dense(50, activation=tf.nn.elu),\n",
        "          tf.keras.layers.Dense(150, activation=tf.nn.elu),\n",
        "          tf.keras.layers.Reshape(target_shape=(6, 25)),\n",
        "          tf.keras.layers.UpSampling1D(size=2),  # 12 x 25\n",
        "          tf.keras.layers.Conv1D(filters=25, kernel_size=3, \n",
        "                                          strides=1, activation=tf.nn.elu, padding='same'),  # 12 x 25\n",
        "          tf.keras.layers.UpSampling1D(size=2),  # 24 x 25\n",
        "          tf.keras.layers.Conv1D(filters=25, kernel_size=3, \n",
        "                                          strides=1, activation=tf.nn.elu, padding='same'),  # 24 x 25\n",
        "          tf.keras.layers.UpSampling1D(size=2),  # 48 x 25\n",
        "          tf.keras.layers.Conv1D(filters=25, kernel_size=5, \n",
        "                                          strides=1, activation=tf.nn.elu, padding='same'),  # 48 x 25\n",
        "          tf.keras.layers.Conv1D(filters=1, kernel_size=1, strides=1),   # 48 x 1\n",
        "          ]\n",
        "      )  \n",
        "\n",
        "  def sample(self, eps=None):\n",
        "      if eps is None:\n",
        "          eps = tf.random_normal(shape=(100, self.latent_dim))\n",
        "      return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "      mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "      return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "      eps = tf.random.normal(shape=mean.shape)\n",
        "      return (eps * tf.exp(logvar * .5)) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "      logits = self.generative_net(z)\n",
        "      if apply_sigmoid:\n",
        "          probs = tf.sigmoid(logits)\n",
        "          return probs\n",
        "      return logits\n",
        "\n",
        "  def compute_loss(self, x, noisy_x):\n",
        "    # Encoder part of the network\n",
        "    if noisy_x is None:\n",
        "      mean, log_var = self.encode(x)\n",
        "    else:\n",
        "      mean, log_var = self.encode(noisy_x)\n",
        "      \n",
        "    if self.is_VAE:\n",
        "      z = self.reparameterize(mean, log_var)\n",
        "    else:\n",
        "      z = mean\n",
        "\n",
        "    # Decoder\n",
        "    x_decoded = self.decode(z)\n",
        "    \n",
        "    # MSE\n",
        "    recons_loss = tf.reduce_sum(tf.math.squared_difference(x, x_decoded), axis=1)\n",
        "    recons_loss = tf.reduce_mean(recons_loss)\n",
        "    \n",
        "    \n",
        "    # KLD\n",
        "    latent_loss = -0.5 * tf.reduce_sum(1 + log_var - tf.square(mean) - tf.exp(log_var), axis=1)\n",
        "    latent_loss = tf.reduce_mean(latent_loss)\n",
        "\n",
        "    return tf.reduce_mean(recons_loss + self.beta * (tf.math.abs(latent_loss - self.capacity))), recons_loss, latent_loss\n",
        "    \n",
        "\n",
        "  def compute_gradients(self, x, noisy_x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss, _, _ = self.compute_loss(x, noisy_x)\n",
        "    return tape.gradient(loss, self.trainable_variables), loss\n",
        "\n",
        "  @staticmethod\n",
        "  def apply_gradients(optimizer, gradients, variables):\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRBhq17MD9S3",
        "colab_type": "text"
      },
      "source": [
        "# Implementation 1 \n",
        "\n",
        "For now we'll simply create the model by calling the model creation function by using its default values. This is because our AE model has a few tricks up its sleeve and we haven't seen all the possible uses and parameters yet. \n",
        "\n",
        "The important parameters are: \n",
        "\n",
        "**ADD_NOISE**\n",
        "\n",
        "> Setting this to `True` will add normally distributed noise to the data ($\\mu = 0; SD = 1$). `False` will use the original data. Considering that the spike waveforms are already noisy, both approaches work well. Try either to see how good the model is. \n",
        "\n",
        "**Mini-batch size**\n",
        "\n",
        "> Since our data is quite small (only 48 samples) we can use large batch sizes, but some caution should be used for mini-batch sizes [greater than\n",
        "512](https://arxiv.org/abs/1606.02228). We can play with the values to trade-off between performance (large values) and model accuracy (small values), as larger batch sizes tend to make the model less precise. \n",
        "\n",
        "> For the sake of speed, we will use a high value of 1024, but feel free to try other values. Setting it to 2048 increases speed but decreases the convergence rate of the model. These values work well on Google Colab, but if you run into memory errors on your local machine, decrease the batch size. \n",
        "\n",
        "**Learning-rate**\n",
        "\n",
        "> How \"fast\" our model learns. Since our batch size is fairly large we can use a large learning rate too. But increasing it further to `1e-1` creates instability and results in `NaN` values. \n",
        "\n",
        "\n",
        "**Training epochs**\n",
        "\n",
        "> The number of passes through the entire training data. We'll run the validation set after each epoch. \n",
        "\n",
        "> If you decreased the batch size, you can train for less epochs to speed everything up. Learning is quite slow at the latter epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaBjkJsxYt2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model parameters\n",
        "# setting this to True will add a normal gaussian noise to the z_scored data\n",
        "# False will train only on the \"clean\" z_scored waveforms\n",
        "ADD_NOISE = False  \n",
        "\n",
        "BATCH_SIZE = 1024  \n",
        "LEARNING_RATE = 1e-2\n",
        "EPOCHS = 25\n",
        "\n",
        "# Model Creation\n",
        "model = betaCVAE(learning_rate=LEARNING_RATE)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "# Dataset creation\n",
        "TRAIN_BUF = train_set.shape[0]\n",
        "VALID_BUF = valid_set.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_set).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_set).shuffle(VALID_BUF).batch(BATCH_SIZE)\n",
        "\n",
        "# Trackers\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "train_time = []\n",
        "valid_time = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnOer6bhapPK",
        "colab_type": "text"
      },
      "source": [
        "### Run functions\n",
        "\n",
        "This AE model is a bit more \"hands-on\" than the previous CNN we used because we'll later need to access some of the inner functions to compute the loss and gradients. \n",
        "\n",
        "Instead of using `model.fit(...)` we will directly call the `model.compute_gratients()` and `model.apply_gradients()` functions. These aren't default tensorflow model functions, they were manually created for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo5y5yPphXQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def train_model(add_noise, out_losses=False):\n",
        "  for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    temp_loss = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    # iterator generator that randomizes the training datasets\n",
        "    for train_x in train_dataset:\n",
        "      if add_noise:\n",
        "          gradients, loss = model.compute_gradients(train_x, train_x + tf.random.normal(shape=train_x.shape))\n",
        "      else:\n",
        "          gradients, loss = model.compute_gradients(train_x, None)\n",
        "        \n",
        "      model.apply_gradients(optimizer, gradients, model.trainable_variables)\n",
        "      temp_loss.append(loss)\n",
        "\n",
        "    train_loss.append(np.mean(temp_loss))\n",
        "    train_time.append(time.time()-start_time)\n",
        "\n",
        "    temp_loss = []\n",
        "    for valid_x in valid_dataset:\n",
        "      if add_noise:\n",
        "        temp, recon, latent = model.compute_loss(valid_x, valid_x + tf.random.normal(shape=valid_x.shape))\n",
        "        temp_loss.append(temp.numpy())\n",
        "      else:\n",
        "        temp, recon, latent = model.compute_loss(valid_x, None)\n",
        "        temp_loss.append(temp.numpy())\n",
        "      if out_losses:\n",
        "        recon_loss.append(recon)\n",
        "        latent_loss.append(latent)\n",
        "        \n",
        "    valid_loss.append(np.mean(temp_loss))\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print('Epoch: {}, Train set loss: {}, Test set loss: {}, '\n",
        "          'time elapsed for current epoch {}'.format(epoch,\n",
        "                                                     train_loss[-1], \n",
        "                                                     valid_loss[-1],\n",
        "                                                    train_time[-1]))\n",
        "\n",
        "# Randomly sample N waveforms from the entire datasets        \n",
        "def get_examples(n_examples, add_noise):\n",
        "  examples = z_wf[np.random.randint(0, z_wf.shape[0], n_examples)]\n",
        "  if add_noise: \n",
        "    examples += np.random.rand(examples.shape[0], examples.shape[1], examples.shape[2])\n",
        "  \n",
        "  return examples\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nd-AmVYlI6Q",
        "colab_type": "text"
      },
      "source": [
        "### (Finally) Run the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "golwnrOBuT9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Add noise = ' + str(ADD_NOISE))\n",
        "train_model(ADD_NOISE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_2EHT8fai41",
        "colab_type": "text"
      },
      "source": [
        "The loss function might still apear high at ~6.7 for both training and testing sets (`ADD_NOISE=False`) but we use the mean sum of squared residuals so: \n",
        "\n",
        "$\\sqrt{(6.7 / 48)} \\approx .37$\n",
        "\n",
        "If we look at what that represents on a real waveform. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzce3jiihrW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss():\n",
        "  # Plot Loss results\n",
        "  fig = plt.figure(figsize=(20,12), facecolor='white')\n",
        "  ax = plt.subplot(231)\n",
        "  plt.plot([x for x in train_loss])\n",
        "  plt.title('Final training loss: ' + str(train_loss[-1]))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.subplot(232, sharey=ax)\n",
        "  plt.plot([x for x in valid_loss])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Final validation loss: ' + str(valid_loss[-1]))\n",
        "\n",
        "  # Plot reconstruction examples\n",
        "  n_to_plot = 10\n",
        "\n",
        "  examples = get_examples(n_to_plot, ADD_NOISE)\n",
        "\n",
        "  m, logvar = model.encode(examples)\n",
        "  x_hat = model.decode(m)\n",
        "\n",
        "  lims = (-5,5)\n",
        "  diffs = np.sqrt(valid_loss[-1]/examples.shape[1])\n",
        "  print('Average error per point: ' + str(diffs))\n",
        "  ax = plt.subplot(234)\n",
        "  plt.plot(examples.squeeze().T)\n",
        "  plt.title('Original waveforms')\n",
        "  plt.ylim(lims)\n",
        "  plt.subplot(235, sharey=ax)\n",
        "  plt.plot(x_hat.numpy().squeeze().T)\n",
        "  plt.title('Reconstructed waveforms ($\\hat{X}$)');\n",
        "  plt.subplot(236, sharey=ax)\n",
        "  plt.plot(examples[0,:,:].squeeze(), 'b')\n",
        "  plt.plot(examples[0,:,:].squeeze()-diffs, '--b')\n",
        "  plt.plot(examples[0,:,:].squeeze()+diffs, '--b')\n",
        "  plt.plot(x_hat[0,:,:].numpy().squeeze(), 'r');\n",
        "  plt.title('$\\hat{X}$ Example 1');\n",
        "  \n",
        "plot_loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcJVeripI91V",
        "colab_type": "text"
      },
      "source": [
        "We can see that the above reconstructed waveforms seem pretty good. Which is expected since it is a very simple task. \n",
        "\n",
        "But keep in mind we have a very narrow bottleneck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8do9NU8r-OO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.latent_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kwMw5RNNNjU",
        "colab_type": "text"
      },
      "source": [
        "### Let's compare with PCA\n",
        "\n",
        "Using the same script as above but for 1000 spikes. \n",
        "\n",
        "The color scale follows the values of the first PC. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwFL86t3Q_eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pca_comp():\n",
        "  # Plot reconstruction examples\n",
        "  # Our AE\n",
        "  n_dim = model.latent_dim  # 2 by default\n",
        "\n",
        "  n_to_plot = 1000\n",
        "  examples = get_examples(n_to_plot, ADD_NOISE)\n",
        "  model_out, _ = model.encode(examples)\n",
        "\n",
        "  # PCA\n",
        "  from sklearn.decomposition import PCA\n",
        "  pca = PCA(n_components=n_dim)\n",
        "  pca_out = pca.fit_transform(examples.squeeze())\n",
        "\n",
        "  min_pca = np.min(pca_out[:,0])\n",
        "  max_pca = np.max(pca_out[:,0])\n",
        "\n",
        "  # Plot results\n",
        "  lims = np.max(\n",
        "            (np.abs(np.min(pca_out)), np.abs(np.max(pca_out)),\n",
        "             np.abs(np.min(model_out)), np.abs(np.max(model_out))))\n",
        "\n",
        "  fig = plt.figure(figsize=(20,6), facecolor='white')\n",
        "  ax1 = plt.subplot(131, ylim=(-lims, lims), title='Z-Scored waveforms')\n",
        "  ax2 = plt.subplot(132, xlim=(-lims, lims), sharey=ax1, title='AE space')\n",
        "  ax3 = plt.subplot(133, sharex=ax2, sharey=ax2, title='PCA space')\n",
        "\n",
        "  for idx, ex in enumerate(examples.squeeze()):\n",
        "    colors = cm.viridis((pca_out[idx,0] - np.min(pca_out))/(np.abs(np.min(pca_out))+np.max(pca_out)))\n",
        "    ax1.plot(ex, color=colors)\n",
        "    ax2.plot(model_out.numpy()[idx,0],model_out.numpy()[idx,1], '.', color=colors)\n",
        "    ax3.plot(pca_out[idx,0],pca_out[idx,1], '.', color=colors)\n",
        "  return model_out, pca_out, pca   \n",
        "\n",
        "model_out, pca_out, pca = pca_comp()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDVzJp5XaCJG",
        "colab_type": "text"
      },
      "source": [
        "The AE latent space is more spread out than the PCA one, and it seems that the two PC dimensions are mingled in the AE representations.\n",
        "\n",
        "The AE feature space is also quite discontinuous meaning that when randomly sampling points to generate waveforms, there is a greater probability of sampling from an empty region which could yield an unrealistic or distorted waveform. \n",
        "\n",
        "Let generate a few and see. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBZaoAKHaiFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wave_generation(model_out, pca_out, pca):\n",
        "  # Model_out feature space\n",
        "  min_model_x = np.min(model_out.numpy()[:,0])\n",
        "  max_model_x = np.max(model_out.numpy()[:,0])\n",
        "  min_model_y = np.min(model_out.numpy()[:,1])\n",
        "  max_model_y = np.max(model_out.numpy()[:,1])\n",
        "  print('VAE generating in the range: \\n x:' +\n",
        "        str(min_model_x) + ' to ' + str(max_model_x) + '\\n y:' +\n",
        "        str(min_model_y) + ' to ' + str(max_model_y))\n",
        "\n",
        "  n_to_generate=10\n",
        "  random_latent_features = np.random.rand(n_to_generate, 2)\n",
        "  model_latent = random_latent_features * np.array(((np.abs(min_model_x) + np.abs(max_model_x)),(np.abs(min_model_y) + np.abs(max_model_y))))\n",
        "  model_latent -= np.array((np.abs(min_model_x), np.abs(min_model_y)))\n",
        "  print('VAE generated samples : \\n ' + str(model_latent) + '\\n')\n",
        "\n",
        "  x_hat = model.decode(model_latent)\n",
        "\n",
        "  fig = plt.figure(figsize=(16,5), facecolor='white')\n",
        "  plt.subplot(121)\n",
        "  plt.plot(x_hat.numpy().squeeze().T)\n",
        "  plt.title('VAE generated waveforms');\n",
        "\n",
        "  # Repeat for PCA\n",
        "  min_pca_x = np.min(pca_out[:,0])\n",
        "  max_pca_x = np.max(pca_out[:,0])\n",
        "  min_pca_y = np.min(pca_out[:,1])\n",
        "  max_pca_y = np.max(pca_out[:,1])\n",
        "  print('PCA generating in the range: \\n x:' +\n",
        "        str(min_pca_x) + ' to ' + str(max_pca_x) + '\\n y:' +\n",
        "        str(min_pca_x) + ' to ' + str(max_pca_y))\n",
        "\n",
        "  pca_latent_features = random_latent_features * np.array(((np.abs(min_pca_x) + np.abs(max_pca_x)),(np.abs(min_pca_y) + np.abs(max_pca_y))))\n",
        "  pca_latent_features -= np.array((np.abs(min_pca_x), np.abs(min_pca_y)))\n",
        "  print('VAE generated samples : \\n ' + str(pca_latent_features) + '\\n')\n",
        "\n",
        "  pca_hat = pca.inverse_transform(pca_latent_features)\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.plot(pca_hat.T)\n",
        "  plt.title('PCA generated waveforms');\n",
        "  return [min_model_x, max_model_x, min_model_y, max_model_y], [min_pca_x, max_pca_x, min_pca_y, max_pca_y]\n",
        "  \n",
        "min_max_model, min_max_pca = wave_generation(model_out, pca_out, pca)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igWSf1A6CkB6",
        "colab_type": "text"
      },
      "source": [
        "### Plot individual features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mo0gkgfCnbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_features(min_max_model, min_max_pca):\n",
        "  from matplotlib.lines import Line2D\n",
        "  custom_lines = [Line2D([0], [0], color='k'),\n",
        "                  Line2D([0], [0], color='b'),\n",
        "                  Line2D([0], [0], color='b', linestyle='--'),\n",
        "                  Line2D([0], [0], color='r'),\n",
        "                  Line2D([0], [0], color='r', linestyle='--')]\n",
        "  n_lin_space = 10\n",
        "\n",
        "  fig = plt.figure(figsize=(25,20), facecolor='white')\n",
        "  gs = fig.add_gridspec(9,n_lin_space + 2)\n",
        "\n",
        "  subs = [fig.add_subplot(gs[1:3,0:2])]\n",
        "  subs.append(fig.add_subplot(gs[6:8,0:2]))\n",
        "\n",
        "  model_x_range = np.linspace(min_max_model[0], min_max_model[1], n_lin_space)\n",
        "  model_y_range = np.linspace(min_max_model[2], min_max_model[3], n_lin_space)\n",
        "  pca_x_range = np.linspace(min_max_pca[0], min_max_pca[1], n_lin_space)\n",
        "  pca_y_range = np.linspace(min_max_pca[2], min_max_pca[3], n_lin_space)\n",
        "\n",
        "  # get N examples\n",
        "  examples = get_examples(2, ADD_NOISE)\n",
        "\n",
        "  model_out, _ = model.encode(examples)\n",
        "  pca_out = pca.transform(examples.squeeze())\n",
        "\n",
        "  for sub, ex in enumerate(examples): \n",
        "\n",
        "    subs[sub].plot(ex,'k')\n",
        "    subs[sub].plot(model.decode(tf.reshape(model_out[sub,:], (1,2))).numpy().squeeze(),'b')\n",
        "    subs[sub].plot(pca.inverse_transform(pca_out[sub,:]),'r')\n",
        "\n",
        "    for idx in range(n_lin_space):\n",
        "      fig.add_subplot(gs[0+(5*sub),idx+2])\n",
        "      plt.plot(model.decode(np.array([model_x_range[idx], model_out[sub,1].numpy()]).reshape(1,2)).numpy().squeeze(), 'b')\n",
        "      plt.title('X={:.2f}; Y={:.2f}'.format(model_x_range[idx], model_out[sub,1].numpy()))\n",
        "\n",
        "      fig.add_subplot(gs[1+(5*sub),idx+2])\n",
        "      plt.plot(model.decode(np.array([model_out[sub,0].numpy(), model_y_range[idx]]).reshape(1,2)).numpy().squeeze(), '--b')\n",
        "      plt.title('X={:.2f}; Y={:.2f}'.format(model_out[sub,0].numpy(), model_y_range[idx]))\n",
        "\n",
        "      fig.add_subplot(gs[2+(5*sub),idx+2])\n",
        "      plt.plot(pca.inverse_transform(np.array([pca_x_range[idx], pca_out[sub,1]]).reshape(1,2)).T, 'r')\n",
        "      plt.title('X={:.2f}; Y={:.2f}'.format(pca_x_range[idx], pca_out[sub,1]))\n",
        "\n",
        "      fig.add_subplot(gs[3+(5*sub),idx+2])\n",
        "      plt.plot(pca.inverse_transform(np.array([pca_out[sub,0], pca_y_range[idx]]).reshape(1,2)).T, '--r')\n",
        "      plt.title('X={:.2f}; Y={:.2f}'.format(pca_out[sub,0], pca_y_range[idx]))\n",
        "\n",
        "  fig.add_subplot(gs[4,0], frame_on=False, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
        "  plt.legend(custom_lines, ['Original', 'AE_X','AE_Y', 'PCA_X', 'PCA_Y']);\n",
        "\n",
        "  for ax in fig.axes:\n",
        "    ax.set_ylim((-6,6))\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])\n",
        "\n",
        "    \n",
        "plot_features(min_max_model, min_max_pca)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cxcpv5-adj-",
        "colab_type": "text"
      },
      "source": [
        "# Implementation 2\n",
        "\n",
        "### Possible to increase density in latent space? \n",
        "\n",
        "We can add a penalty term to our reconstruction loss function to force a specific latent representation. \n",
        "\n",
        "For example, we can force the latent variables to follow a unit Gaussian shape. ($\\beta=1$)\n",
        "\n",
        "Wich is a **Variational Auto-Encoder**.\n",
        "\n",
        "\n",
        "\n",
        "If we re-run the cells above to re-plot, we see that the VAE latent representation is much more compact. This allows us to have a uniform latent space in order to generate believable waveforms. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3vjM49qTNxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model parameters\n",
        "BETA = 1.\n",
        "BATCH_SIZE = 1024  \n",
        "LEARNING_RATE = 1e-2\n",
        "EPOCHS = 25\n",
        "\n",
        "# Model Creation\n",
        "model = betaCVAE(learning_rate=LEARNING_RATE, beta=BETA)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "# Dataset creation\n",
        "TRAIN_BUF = train_set.shape[0]\n",
        "VALID_BUF = valid_set.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_set).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_set).shuffle(VALID_BUF).batch(BATCH_SIZE)\n",
        "\n",
        "# Trackers\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "train_time = []\n",
        "valid_time = []\n",
        "\n",
        "train_model(ADD_NOISE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTxU8azkgaWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to re-run the above plots\n",
        "plot_loss()\n",
        "model_out, pca_out, pca = pca_comp()\n",
        "min_max_model, min_max_pca = wave_generation(model_out, pca_out, pca)\n",
        "plot_features(min_max_model, min_max_pca)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u__d277d9lym",
        "colab_type": "text"
      },
      "source": [
        "# Implementation 3\n",
        "\n",
        "In this section we will use the capacity parameter and linearly increase it with training to for the network to learn disentangled representations. \n",
        "\n",
        "This is taken from [Burgess et al.,2018](http://arxiv.org/abs/1804.03599).\n",
        "\n",
        "In a nutshell, by using a large $\\beta$ value, the network prioritizes the KL divergence term of the loss function and doesn't learn to reconstruct the data at the beginning of training (i.e. capacity = 0). It basically models the data mean. \n",
        "\n",
        "The capacity term is added to the loss function where: \n",
        "\n",
        "$Loss = Reconstruction \\space loss + \\beta (KL \\space divergence - capacity)$\n",
        "\n",
        "This means that when we increase the capacity of the network, we slowly reduce the importance of the KL divergence term, allowing the network to slowly increase it's reconstruction capacity. \n",
        "\n",
        "The followin cell plots the latent space of a few example waveforms. Throught training we can see that the network first separates the data along one dimension, and later along the second one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRFKr1oH7iw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "import time\n",
        "# Model Creation\n",
        "# Model parameters\n",
        "ADD_NOISE = False \n",
        "BETA = 20.  # actually gamma parameter in the paper\n",
        "CAPACITY_MAX = 2\n",
        "CAPACITY_ANN = 50\n",
        "CAPACITY_STEP = 1\n",
        "\n",
        "BATCH_SIZE = 1024  \n",
        "LEARNING_RATE = 1e-2\n",
        "EPOCHS = 1\n",
        "model = betaCVAE(learning_rate=LEARNING_RATE, beta=BETA, capacity=0., latent_dim=2)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "# Dataset creation\n",
        "TRAIN_BUF = train_set.shape[0]\n",
        "VALID_BUF = valid_set.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_set).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_set).shuffle(VALID_BUF).batch(BATCH_SIZE)\n",
        "\n",
        "# Trackers\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "train_time = []\n",
        "valid_time = []\n",
        "recon_loss = []\n",
        "latent_loss = []\n",
        "\n",
        "plt.ion()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_xlim((-5,5))\n",
        "ax.set_ylim((-5,5))\n",
        "line = ax.plot(0,0,'.')\n",
        "\n",
        "n_to_plot = 500\n",
        "examples = get_examples(n_to_plot, ADD_NOISE)\n",
        "\n",
        "for x in range(CAPACITY_ANN+1):\n",
        "  if x % CAPACITY_STEP == 0 and x > 0:\n",
        "    model.capacity += CAPACITY_MAX / (CAPACITY_ANN / CAPACITY_STEP)\n",
        "  \n",
        "  train_model(ADD_NOISE, out_losses=True);\n",
        "  capacity_trained = model.encode(examples)[0].numpy().squeeze()\n",
        "  line[0].set_xdata(capacity_trained[:,0])\n",
        "  line[0].set_ydata(capacity_trained[:,1])\n",
        "  ax.set_title(str(x))\n",
        "  display.clear_output()\n",
        "  display.display(plt.gcf())\n",
        "  time.sleep(.001) \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6jhHZ-gtjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to re-run the above plots\n",
        "plot_loss()\n",
        "model_out, pca_out, pca = pca_comp()\n",
        "min_max_model, min_max_pca = wave_generation(model_out, pca_out, pca)\n",
        "plot_features(min_max_model, min_max_pca)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO6qYFk2HiJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a new plot to see if this improves spike clustering.\n",
        "# With a basic threshold across horizontal and vertical dimensions, \n",
        "# we can clearly see good waveform separations. At this point adding\n",
        "# a clustering metric is trivial. \n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "threshold = 1.\n",
        "ax1 = plt.subplot(121, xlim=(-4,4), ylim=(-4,4))\n",
        "ax2 = plt.subplot(122)\n",
        "for id, pair in enumerate(capacity_trained[:,:]):\n",
        "  colormap = .5 * np.add(cm.bwr((pair[0]+4)/8), cm.PiYG((pair[1]+4)/8))\n",
        "  \n",
        "  ax1.plot(pair[0], pair[1], '.', color=colormap)\n",
        "  ax2.plot(examples[id,:], color=colormap);\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNhhu9YGBIYd",
        "colab_type": "text"
      },
      "source": [
        "In the paper $\\beta$ is renamed $\\gamma$ and capacity is defined as C. \n",
        "\n",
        "**How to Tune Hyperparameters Gamma and C? (Response by Christopher P. Burgess)**\n",
        "\n",
        "Gamma sets the strength of the penalty for deviating from the target KL, C. Here you want to tune this such that the (batch) average KL stays close to C (say within < 1 nat) across the range of C that you use. This exact value doesn't usually matter much, but just avoid it being too high such that it destabilises the optimisation. C itself should start from low (e.g. 0 or 1) and gradually increase to a value high enough such that reconstructions end up good quality. A good way to estimate Cmax is to train B-VAE on your dataset with a beta low enough such that reconstructions end up good quality and look at the trained model's average KL. That KL can be your Cmax because it gives you a rough guide as to the average amount of representational capacity needed to encode your dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l4LG9QeZkQy",
        "colab_type": "text"
      },
      "source": [
        "### Informative blog posts and further reading\n",
        "\n",
        "#### ($\\beta$)(V)AE\n",
        "\n",
        "[AE in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
        "\n",
        "[AE](https://www.jeremyjordan.me/autoencoders/)\n",
        "\n",
        "[VAE](https://www.jeremyjordan.me/variational-autoencoders/)\n",
        "\n",
        "[VAE to BVAE](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)\n",
        "\n",
        "[$\\beta$-VAE and disentanglement](https://towardsdatascience.com/what-a-disentangled-net-we-weave-representation-learning-in-vaes-pt-1-9e5dbc205bd1)\n",
        "\n",
        "#### (de)Convolution\n",
        "[Convolution arithmetic](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)\n",
        "\n",
        "[Deconvolution vs upsampling and convolution](https://distill.pub/2016/deconv-checkerboard/)\n",
        "\n",
        "\n",
        "#### Loss functions\n",
        "[Binary cross-entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)\n",
        "\n",
        "[Entropy, MLE, NLL](https://jhui.github.io/2017/01/05/Deep-learning-Information-theory/)\n",
        "\n",
        "[VAE Demo](https://github.com/omerbsezer/Generative_Models_Tutorial_with_Demo#whatisGM)\n",
        "\n",
        "#### General Tips\n",
        "[Training tips](https://karpathy.github.io/2019/04/25/recipe/)\n",
        "\n",
        "\n",
        "#### Research papers (same as ppt)\n",
        "[Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: Evidence from whole-brain resting-state functional connectivity patterns of schizophrenia.](https://www.ncbi.nlm.nih.gov/pubmed/25987366)\n",
        "\n",
        "[Latent feature representation with stacked auto-encoder for AD/MCI diagnosis.](https://www.ncbi.nlm.nih.gov/pubmed/24363140)\n",
        "\n",
        "[A Stacked Sparse Autoencoder-Based Detector for Automatic Identification of Neuromagnetic High Frequency Oscillations in Epilepsy.](https://www.ncbi.nlm.nih.gov/pubmed/29994761)\n",
        "\n",
        "[Stacked Autoencoders for the P300 Component Detection.](https://www.ncbi.nlm.nih.gov/pubmed/28611579)\n",
        "\n",
        "[Semi-supervised Stacked Label Consistent Autoencoder for Reconstruction and Analysis of Biomedical Signals.](https://www.ncbi.nlm.nih.gov/pubmed/27893378)\n",
        "\n",
        "[A stacked contractive denoising auto-encoder for ECG signal denoising.](https://www.ncbi.nlm.nih.gov/pubmed/27869101)\n",
        "\n",
        "[Automatic Sleep Stage Scoring Using Time-Frequency Analysis and Stacked Sparse Autoencoders.](https://www.ncbi.nlm.nih.gov/pubmed/26464268)\n",
        "\n",
        "[Feature extraction with stacked autoencoders for epileptic seizure detection.](https://www.ncbi.nlm.nih.gov/pubmed/25570914)\n",
        "\n",
        "[A novel deep learning approach for classification of EEG motor imagery signals.](https://www.ncbi.nlm.nih.gov/pubmed/27900952)\n",
        "\n",
        "[Inter-subject transfer learning with an end-to-end deep convolutional neural network for EEG-based BCI.](https://www.ncbi.nlm.nih.gov/pubmed/30524056)"
      ]
    }
  ]
}